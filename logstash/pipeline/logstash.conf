input {
  kafka {
    topics_pattern  => "kafka-log-.*"
    bootstrap_servers => "kafka:9092"
    auto_offset_reset => "earliest"
    consumer_threads => 5
    decorate_events => "true"
  }
}

filter {
  grok {
    match => {
      originInfo => "\[(?<date>.*?)\]\[(?<level>.*?)\]\[(?<pid>.*?)\]\[(?<thread>.*?)\]\[(?<class>.*?)\]\[(?<line>.*?)\](?<message>.*)"
    }
  }

  mutate {
    add_field => {
      "logtime" => "%{date}"
    }
  }

  date {
    timezone => "Asia/Shanghai"
    match => ["logtime", "yyyy-MM-dd HH:mm:ss.SSS"]
    target => "@timestamp"
    remove_field => [ "logtime" ]
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "%{[@metadata][kafka][topic]}-%{+YYYY-MM-dd}"
    user => "elastic"
    password => "changeme"
  }
  stdout {
    codec => rubydebug
  }
}

